1.) Import necessary Libraries (Sentiment Phase)
    - datetime ---> timedelta
    - request
    - pandas ---> DataFrame
    - nltk.sentiment.vader ---> SentimentIntensityAnalyzer

2.) Select API Source:
    -NewsAPI
        -Parameters:
                 {
                'q': 'artificial intelligence',  # Query keyword
                'from': 'y-m-d',            # Start date; must be before end date
                'to': 'y-m-d',              # End date; must be after start date
                'sortBy': 'relevancy',           # Sort by relevancy
                'language': 'en',                # Language of the articles
                'pageSize': 20,                  # Number of results per page
                'apiKey': api_key                # Your API key
                }

3.) Strategically input values into query
    - datetime, timedelta functionalities in use

4.) Get API data and convert to JSON
    - Request functionality in use

5.) Retrieve the article titles
    -Since the retrieved data is in dictionary format, pin point the 'Title' locations through nested indexing and append titles to a title list

6.) Create a dataframe that will organize Title along with it's appended sentiment score
    - Pandas ---> DataFrame
    - SentimentAnalyzer

    ---------------------------------------------------------------------

    Goals for week 4

        - Import Kafka for real-time streams of News data
        -Import Alpha Vantage for stock data

        - Find a brokage account to try and implement real-time access



----------------------------------------------------------------
Goals for week 6:

    -Implement time tags (DONE)
    -utilize the different GET urls I was recommended by Professor Kaamran
    - (BETTER The RELEVENT STOCKS)